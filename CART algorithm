The CART (Classification and Regression Trees) algorithm is commonly used for building decision trees, and it operates by splitting the dataset into subsets based on feature values to maximize information gain. Here, I'll guide you through implementing a decision tree using CART in Python, using sklearn. We'll then address overfitting using a pruning technique called post-pruning (also known as cost complexity pruning in sklearn).

Steps
Load a dataset, like the Iris dataset for classification.
Train a decision tree using the CART algorithm.
Apply the model to classify a new sample.
Analyze overfitting by evaluating the model’s performance on training vs. testing data.
Implement pruning to reduce overfitting.
Code Example
python
Copy code
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import classification_report, accuracy_score
import matplotlib.pyplot as plt

# Load a dataset (Iris dataset for simplicity)
data = load_iris()
X = data.data
y = data.target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 1: Train a Decision Tree using the CART algorithm
# Initialize the Decision Tree with no pruning (to observe overfitting)
tree_classifier = DecisionTreeClassifier(random_state=42)
tree_classifier.fit(X_train, y_train)

# Make predictions on training and test sets
y_train_pred = tree_classifier.predict(X_train)
y_test_pred = tree_classifier.predict(X_test)

# Evaluate performance
print("Training Accuracy:", accuracy_score(y_train, y_train_pred))
print("Test Accuracy:", accuracy_score(y_test, y_test_pred))

# Classification Report
print("\nClassification Report on Test Data:")
print(classification_report(y_test, y_test_pred))

# Step 2: Visualize the tree (unpruned)
plt.figure(figsize=(12, 8))
plot_tree(tree_classifier, feature_names=data.feature_names, class_names=data.target_names, filled=True)
plt.title("Decision Tree Before Pruning")
plt.show()

# Step 3: Address overfitting by pruning (Cost Complexity Pruning)
# Set the ccp_alpha value for post-pruning to avoid overfitting (found via grid search or experimentation)
path = tree_classifier.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas = path.ccp_alphas  # Array of effective alphas
tree_pruned = []

# Train trees for each alpha to observe impact
for ccp_alpha in ccp_alphas:
    clf = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)
    clf.fit(X_train, y_train)
    tree_pruned.append(clf)

# Evaluate accuracy vs alpha
train_scores = [clf.score(X_train, y_train) for clf in tree_pruned]
test_scores = [clf.score(X_test, y_test) for clf in tree_pruned]

# Plot the effect of pruning on accuracy
plt.figure(figsize=(10, 6))
plt.plot(ccp_alphas, train_scores, marker='o', label="Training Accuracy")
plt.plot(ccp_alphas, test_scores, marker='o', label="Testing Accuracy")
plt.xlabel("Alpha")
plt.ylabel("Accuracy")
plt.title("Accuracy vs. Alpha for Training and Testing sets")
plt.legend()
plt.show()

# Choose the best model based on the alpha that maximizes test accuracy
best_alpha = ccp_alphas[np.argmax(test_scores)]
pruned_tree = DecisionTreeClassifier(random_state=42, ccp_alpha=best_alpha)
pruned_tree.fit(X_train, y_train)

# Evaluate the pruned tree on test data
y_test_pruned_pred = pruned_tree.predict(X_test)
print("\nClassification Report on Test Data (Pruned):")
print(classification_report(y_test, y_test_pruned_pred))

# Visualize the pruned tree
plt.figure(figsize=(12, 8))
plot_tree(pruned_tree, feature_names=data.feature_names, class_names=data.target_names, filled=True)
plt.title("Decision Tree After Pruning")
plt.show()
Explanation of Code
Train Decision Tree Without Pruning:

We initialize a DecisionTreeClassifier without specifying any pruning (ccp_alpha=0 by default), so it builds a fully grown tree. We then evaluate its accuracy on both training and test sets.
Overfitting Observation:

If the training accuracy is significantly higher than the test accuracy, it indicates overfitting. This often happens in decision trees when the model tries to fit every detail in the training data.
Cost Complexity Pruning:

We use cost complexity pruning to control the complexity of the decision tree.
ccp_alpha controls pruning by penalizing additional leaf nodes. Higher ccp_alpha values lead to more aggressive pruning.
We iterate over different ccp_alpha values to train multiple trees and observe their accuracy on both training and test sets.
Selecting Best ccp_alpha:

We choose the ccp_alpha that maximizes test accuracy, then retrain the decision tree with this ccp_alpha value.
Visualize Pruned Tree:

The pruned tree is smaller and less complex, helping to reduce overfitting and likely generalizing better to new samples.
Overfitting and Pruning
Overfitting occurs when the model memorizes the training data patterns rather than generalizing from them, leading to poor performance on new data.
Pruning (reducing the tree’s complexity) is an effective solution. Here, cost complexity pruning (post-pruning) controls tree depth and leaf size by penalizing the addition of new branches.
